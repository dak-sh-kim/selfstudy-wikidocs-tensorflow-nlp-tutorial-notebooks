{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "20220616_NLP_2-08)  One-Hot Encoding .ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNLOGagb7pwPiXQjFmzE90/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dak-sh-kim/selfstudy-wikidocs-tensorflow-nlp-tutorial-notebooks/blob/main/20220616_NLP_2_08)_One_Hot_Encoding_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 컴퓨터/기계는 문자보다는 숫자를 더 잘 처리 할 수 있음\n",
        "- 원핫인코딩 (One-Hot-Encoding은 그 많은 기법 중, 단어를 표현하는 가장 기본적인 표현 방법. 문자 --> 벡터\n",
        "- 머신러닝, 딥 러닝을 하기 위해서는 반드시 배워야 하는 표현 방법"
      ],
      "metadata": {
        "id": "aUjjIQEjR3Qr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "'단어집합(vocabulary)'\n",
        "- \"서로 다른\" 단어들의 집합 (텍스트 모든 단어를 중복 허용 없이 모아놓은 것)\n",
        "- \"서로 다른\" = 단어 원형의 변형 형태도 다른 단어로 간주\n",
        "- e.g. books != book"
      ],
      "metadata": {
        "id": "OFEompWdWihq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "'정수 인코딩'\n",
        "- e.g. 텍스트에 단어가 5000개 존재한다면, 단어집합의 크기는 5000\n",
        "- 1~5000까지 숫자가 부여된 단어 집합 존재.  e.g. god = 122번, love = 3333번\n",
        "- 이 숫자로 바뀐 단어들을 '벡터'로 다루고 싶다면?"
      ],
      "metadata": {
        "id": "oneslp6cXDS0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. 원-핫 인코딩 (One-Hot Encoding)이란?"
      ],
      "metadata": {
        "id": "McYQGN0TXkmA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 단어집합의 크기 = 벡터의 차원\n",
        "- 표현하고 싶은 단어의 인덱스에 1의 값 부여, 다른 인덱스에 0의 값 부여하는 단어의 벡터 표현 방식\n",
        "- 결과물: 원-핫 벡터 (One-Hot vector)\n",
        "- 과정 1) 정수 인코딩\n",
        "- 과정 2) 고유한 정수를 인덱스로 간주, 해당 위치에 1 부여, 다른 위치 0 부여"
      ],
      "metadata": {
        "id": "yLqTC0mLXsve"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 한국어 문장을 예제로 한 원-핫 벡터 예제"
      ],
      "metadata": {
        "id": "Bp-7GNZhX99J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 문장: '나는 자연어 처리를 배운다'"
      ],
      "metadata": {
        "id": "sc2hsnxrYMMm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install konlpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1RzMqwSZG-n",
        "outputId": "9566f6a4-3d66-4354-e31a-f13b078305d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4 MB 7.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.21.6)\n",
            "Collecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.4.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (453 kB)\n",
            "\u001b[K     |████████████████████████████████| 453 kB 30.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (4.1.1)\n",
            "Installing collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.4.0 konlpy-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Okt 형태소 분석기를 통해 문장에 대한 토큰화 수행\n",
        "from konlpy.tag import Okt\n",
        "okt = Okt()\n",
        "tokens = okt.morphs('나는 자연어 처리를 배운다')\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2qfzDMvYRhD",
        "outputId": "21b39789-2db9-45e5-a148-3e4ff59c7d31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['나', '는', '자연어', '처리', '를', '배운다']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 지금은 문장이 짧기 때문에 각 단어의 빈도수를 고려하지 않지만, \n",
        "# 빈도수 순으로 단어를 정렬하여 정수를 부여하는 경우가 많음\n",
        "\n",
        "word_to_index = {word: index for index, word in enumerate(tokens)}\n",
        "print('단어 집합: ', word_to_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "meoc-XwHZFtL",
        "outputId": "a767110c-83a3-47cc-d895-b1d182d3fbc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 집합:  {'나': 0, '는': 1, '자연어': 2, '처리': 3, '를': 4, '배운다': 5}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 토큰을 입력하면 해당 토큰에 대한 원-핫 벡터를 만들어내는 함수"
      ],
      "metadata": {
        "id": "uBMWR3t6fqKQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot_encoding(word, word_to_index): \n",
        "  one_hot_vector = [0]*len((word_to_index)) # [0] * 8 의 결과값: [0, 0, 0, 0, 0, 0, 0, 0]\n",
        "  index = word_to_index[word] # 단어집합에서의 word 에 해당하는 숫자 value --> index 임\n",
        "  one_hot_vector[index] = 1 # [0, 0, 0, 0, 0, 0, 0 ,0] 에서 index해당하는 쪽 1로 바꿈\n",
        "  return one_hot_vector # 리스트로 반환"
      ],
      "metadata": {
        "id": "wbk7b4YNf9C2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- '자연어'라는 단어의 원-핫 벡터를 얻어봅시다."
      ],
      "metadata": {
        "id": "kTlvwxAygSzu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "one_hot_encoding('자연어', word_to_index) # '자연어'는 정수 2이므로, 원-핫 벡터는 인덱스 2의 값이 1, 나머지 값은 0인 벡터"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65Cw5AnHj718",
        "outputId": "31aeec6d-b267-4d28-aa93-c42c4f0d2da0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 0, 1, 0, 0, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. 케라스를 이용한 원-핫 인코딩 (One-Hot Encoding)"
      ],
      "metadata": {
        "id": "M1ko-pscm42w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 케라스는 원-핫 인코딩을 수행하는 유용한 도구 to_categorical() 지원\n",
        "- 케라스만으로 정수 인코딩과 원-핫 인코딩을 진행 가능"
      ],
      "metadata": {
        "id": "9SaROTzvn86l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = '나랑 점심 먹으러 갈래 점심 메뉴는 햄버거 갈래 갈래 햄버거 최고야'"
      ],
      "metadata": {
        "id": "16qBOHisoXDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "text = '나랑 점심 먹으러 갈래 점심 메뉴는 햄버거 갈래 갈래 햄버거 최고야'\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([text]) # 단어집합 만들기\n",
        "print('단어 집합:' , tokenizer.word_index)"
      ],
      "metadata": {
        "id": "lUI4fDxrohqh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7db99e2-3605-49bc-da43-20a3bbf64936"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 집합: {'갈래': 1, '점심': 2, '햄버거': 3, '나랑': 4, '먹으러': 5, '메뉴는': 6, '최고야': 7}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 위와 같이 생성된 단어 집합(vocabulary)에 있는 단어들로만 구성된 텍스트가 있다면, texts_to_sequences()를 통해 정수 시퀀스로 변환 가능"
      ],
      "metadata": {
        "id": "h22sV3suo1ge"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sub_text = '점심 먹으러 갈래 메뉴는 햄버거 최고야'\n",
        "encoded = tokenizer.texts_to_sequences([sub_text])[0] # tokenizer.fit_on_texts([text]) 를 통해 만든 단어집합을 이용함 \n",
        "                      # texts_to_(THE: 이미 만든 vocab)_sequences임\n",
        "print(encoded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGyp5XwVwJL5",
        "outputId": "b5821958-24bc-4c79-f4b0-98ccbfd20b7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2, 5, 1, 6, 3, 7]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 원핫인코딩 시행\n",
        "- keras는 정수 인코딩 된 결과 text_to_sequences()로부터 원-핫 인코딩을 수행하는 to_categorical()을 지원"
      ],
      "metadata": {
        "id": "qXXWhqPIwTBh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "one_hot = to_categorical(encoded)\n",
        "print(one_hot) # \"점심 먹으러 갈래 메뉴는 햄버거 최고야\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_9Hnp5OwYt-",
        "outputId": "a6c1d4ff-fe24-420f-a656-3420cd74fb24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(one_hot[0], \"--> Index 2의 원-핫 벡터\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYJ5G5aZxGk3",
        "outputId": "26aef9a0-a3c6-45b4-8fe5-9252ddc7d4c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0. 0. 1. 0. 0. 0. 0. 0.] --> Index 2의 원-핫 벡터\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. 원-핫 인코딩(One-Hot-Encoding)의 한계"
      ],
      "metadata": {
        "id": "57Hrs62GxLhw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1) 단어 갯수가 늘어날수록, 벡터 저장 공간이 계속 늘어남 "
      ],
      "metadata": {
        "id": "fYaXw8uxxfEY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- = 벡터의 차원이 늘어남\n",
        "- 단어집합의 크기가 = 벡터의 차원 수\n",
        "- ex. 단어가 1000개인 코퍼스로 원-핫 벡터 만들면, 하나의 값만 1을 가지고 999개의 값은 0을 가지는 벡터\n",
        "- 이런 벡터는 저장공간 측면에서 매우 비효율적"
      ],
      "metadata": {
        "id": "qyp0J3nJxsj_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2) 단어의 유사도를 표현하지 못함"
      ],
      "metadata": {
        "id": "c5mxHxpYx7Lt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- ex. [늑대, 호랑이, 강아지, 고양이] 라는 4개의 단어에 대해 각각 [1,0,0,0], [0,1,0,0], [0,0,1,0], [0,0,0,1] 이라는 원-핫 벡터 부여\n",
        "- 이 때, 원-핫 벡터로는 강아지-늑대, 호랑이-고양이의 유사성 표현할 수 없음.\n",
        "- 강아지, 개, 냉장고여도 강아지라는 단어가 개와 냉장고라는 단어 중 어떤 단어가 유사한 지 알 수 없음"
      ],
      "metadata": {
        "id": "JxZqBseQyAMG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*검색시스템 등에서는 문제가 될 소지가 있음.\n",
        "- ex. '삿포로 숙소' 검색, 제대로 되었다면 '삿포로 게스트하우스', '삿포로 료칸', '삿포로 호텔'과 같은 유사단어 결과도 함께 보여줘야 함\n",
        "- 그러나 단어간 유사성 계산이 불가능하다면, '게스트하우스', '료칸', '호텔' 연관검색어 출력 불가능 "
      ],
      "metadata": {
        "id": "8wEQySX7ywfL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*문제--> 단점 해결을 위해 단어의 잠재의미 반영하여 다차원 공간에 벡터화 하는 기법 두 가지 있음\n",
        "- 1) 카운트 기반의 벡터화 방법인 LSA(잠재 의미 분석), HAL\n",
        "- 2) 예측 기반으로 벡터화하는 NNLM, RNNLM, Word2Vec, FastText\n",
        "- 3) 카운트 + 예측 기반 벡터화: GloVe\n",
        "- 이 방법들 대부분은 워드임베딩 챕터에서 다루게 됨"
      ],
      "metadata": {
        "id": "bk4Rp1J-zGh_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "VeNGCW5lzc7R"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}